{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Learning Note - Recommendation\n",
    "Jia Geng | gjia0214@gmail.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://unknown40A5EF2BBD8A:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MLexample</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fae5044e910>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('MLexample').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Alternative Least Square and Collaborate Filtering\n",
    "\n",
    "Spark have an implementatoin of Alternative Least Squares for Collaborative Filterinig. ALS finds a dimentional featue vector for each user an item such that the dot product of each user's feature vector with each item's feature vector approximates the user's rating for that item. The dataset should includes existing ratings between user-item pairs:\n",
    "- a user ID column (need to be int)\n",
    "- an item ID column (need to be int)\n",
    "- a rating column (need to be a float)\n",
    "    - the rating can be explicit: a numerical rating that the system should predict directly\n",
    "    - or implicit: rating represents the strength of interactions between a user and item (e.g. number of visits to a particular page)\n",
    "\n",
    "The goal for recommendation system is that: given an ipnut data frame, the model will produce feature vectors that can be used to predict user's rating for items they have not yet rated.\n",
    "\n",
    "Some potential problem of such system - **cold start problems**:\n",
    "- when introducing a new product that no user has expressed a preference for, the algorithm is not going to recommend it to many people.\n",
    "- if a new user are onboarding onto the platform, they might not have many ratings yet. Therefore the algorithm won't know what to recommend them.\n",
    "\n",
    "The MLlib can scale the algorithm to millions of users, millions of items and billions of ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Params \n",
    "\n",
    "**Hyperparams**\n",
    "\n",
    "|Name|Input|Notes|\n",
    "|-|-|-|\n",
    "|rank|int|the dimension of the feature vectors learned for users and items. **Controls the bias and variance trade off.** Default is 10. \n",
    "|alpha|float|default is 1.0\n",
    "|regParam|float|default is 0.1\n",
    "|implicitPrefs|bool|whether training on implicit or explicit. default is explicity\n",
    "|nonnegative|bool|whether to place a non-negative (feature) constriants on the least square problem. default is False.\n",
    "\n",
    "**Training Params**\n",
    "\n",
    "|Name|Input|Notes|\n",
    "|-|-|-|\n",
    "|numUserBlocks|int|how many blocks to split the user into. default is 10|\n",
    "|numItemBlocks|int|how many blocks to split the items into. default is 10|\n",
    "|maxIter|int|total number of iterations over the data before stopping. default is 10\n",
    "|checkpointInterval|int|allow saving the checkpoints during training\n",
    "|seed|int|random seed for replicating results\n",
    "\n",
    "**Prediction Params**\n",
    "\n",
    "|Name|Input|Notes|\n",
    "|-|-|-|\n",
    "|coldStartStrategy|'nan', 'drop'| strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: alpha for implicit preference (default: 1.0)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "coldStartStrategy: strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'. (default: nan)\n",
      "finalStorageLevel: StorageLevel for ALS model factors. (default: MEMORY_AND_DISK)\n",
      "implicitPrefs: whether to use implicit preference (default: False)\n",
      "intermediateStorageLevel: StorageLevel for intermediate datasets. Cannot be 'NONE'. (default: MEMORY_AND_DISK)\n",
      "itemCol: column name for item ids. Ids must be within the integer value range. (default: item)\n",
      "maxIter: max number of iterations (>= 0). (default: 10)\n",
      "nonnegative: whether to use nonnegative constraint for least squares (default: False)\n",
      "numItemBlocks: number of item blocks (default: 10)\n",
      "numUserBlocks: number of user blocks (default: 10)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "rank: rank of the factorization (default: 10)\n",
      "ratingCol: column name for ratings (default: rating)\n",
      "regParam: regularization parameter (>= 0). (default: 0.1)\n",
      "seed: random seed. (default: 4839091645617282841)\n",
      "userCol: column name for user ids. Ids must be within the integer value range. (default: user)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "print(ALS().explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
