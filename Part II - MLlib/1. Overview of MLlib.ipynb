{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Learning Note - MLlib\n",
    "Jia Geng | gjia0214@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Machine Learning Examples\n",
    "\n",
    "Supervised Learning\n",
    "- classification\n",
    "    - predicting disease\n",
    "    - clasifying image\n",
    "- regression\n",
    "    - predicting sales\n",
    "    - predicting number of viewer of a show\n",
    "    \n",
    "Recommendation\n",
    "- movie recommendation\n",
    "- product recommendation\n",
    "\n",
    "Unsupervised Learning\n",
    "- anormaly detection\n",
    "- user segmentation \n",
    "- topic modeling\n",
    "\n",
    "Graph Analysis\n",
    "- fraud prediction\n",
    "    - interesting - account within two hops of fraudulent number might be considered as suspicious\n",
    "- anormaly detection\n",
    "    - e.g. if typically in the data each vertex has ten edges associated with it. given a vertex only has one edge -> possible anormaly\n",
    "- classification\n",
    "    - influencer's network has similar structure\n",
    "- recommendation\n",
    "    - PageRank is a graph algorithm!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic ML Developmental Stages\n",
    "\n",
    "- collect data\n",
    "- clean data\n",
    "- feature engineering\n",
    "- modeling\n",
    "- evaluating and tuning\n",
    "- leveraging model/insights\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark MLlib \n",
    "\n",
    "Spark MLlib provide two core packages for machine learning;\n",
    "- `pyspark.ml`: provide high level DataFrames APIs for building machine learning piplines\n",
    "- `pyspark.mllib`: provide low level RDD APIs\n",
    "\n",
    "\n",
    "**Spark MLlib vs Other ML packages**\n",
    "- most of other ml packages are **single machine tools**\n",
    "- when to use MLlib?\n",
    "    - when data is large, use MLlib for feature engineering then use single machine tool for modeling\n",
    "    - when data and model are both large and can not fit on one machine, MLlib makes distributed machine learning very simple\n",
    "- potential disadvantage of MLlib\n",
    "    - When deploying the model, MLlib does not have buildin to serve low-latency predictions from a model\n",
    "    - Might want to export the model to another serving system or custom application to do it\n",
    "    \n",
    "**Spark Structual Types**\n",
    "- Transformers: functions convert raw data in some way\n",
    "- Estimators\n",
    "    - can a a kind of transformer than is initialized data, e.g. normalize data need to get the mean and std from data\n",
    "    - algorithms that allow users to train a model from data\n",
    "- Evaluator: provide insight about how a model performs according to some criteria we specified such as AUC.\n",
    "- Pipeline: a container hat pipelining the process, like the scikit-learn pipeline\n",
    "\n",
    "\n",
    "**Spark Low Level Data Types**\n",
    "- `from pyspark.ml.linalg import Vectors`\n",
    "- Dense Vector: `Vector.dense(1.0, 2.0, 3.0)`\n",
    "- Spark Vector: `Vector.sparse(size, idx, values)` idx for positions that is not zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example Walk Through\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
