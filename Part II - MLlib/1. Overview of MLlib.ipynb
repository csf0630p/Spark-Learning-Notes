{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Learning Note - MLlib\n",
    "Jia Geng | gjia0214@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Machine Learning Examples\n",
    "\n",
    "Supervised Learning\n",
    "- classification\n",
    "    - predicting disease\n",
    "    - clasifying image\n",
    "- regression\n",
    "    - predicting sales\n",
    "    - predicting number of viewer of a show\n",
    "    \n",
    "Recommendation\n",
    "- movie recommendation\n",
    "- product recommendation\n",
    "\n",
    "Unsupervised Learning\n",
    "- anormaly detection\n",
    "- user segmentation \n",
    "- topic modeling\n",
    "\n",
    "Graph Analysis\n",
    "- fraud prediction\n",
    "    - interesting - account within two hops of fraudulent number might be considered as suspicious\n",
    "- anormaly detection\n",
    "    - e.g. if typically in the data each vertex has ten edges associated with it. given a vertex only has one edge -> possible anormaly\n",
    "- classification\n",
    "    - influencer's network has similar structure\n",
    "- recommendation\n",
    "    - PageRank is a graph algorithm!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic ML Developmental Stages\n",
    "\n",
    "- collect data\n",
    "- clean data\n",
    "- feature engineering\n",
    "- modeling\n",
    "- evaluating and tuning\n",
    "- leveraging model/insights\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark MLlib \n",
    "\n",
    "Spark MLlib provide two core packages for machine learning;\n",
    "- `pyspark.ml`: provide high level DataFrames APIs for building machine learning piplines\n",
    "- `pyspark.mllib`: provide low level RDD APIs\n",
    "\n",
    "\n",
    "**Spark MLlib vs Other ML packages**\n",
    "- most of other ml packages are **single machine tools**\n",
    "- when to use MLlib?\n",
    "    - when data is large, use MLlib for feature engineering then use single machine tool for modeling\n",
    "    - when data and model are both large and can not fit on one machine, MLlib makes distributed machine learning very simple\n",
    "- potential disadvantage of MLlib\n",
    "    - When deploying the model, MLlib does not have buildin to serve low-latency predictions from a model\n",
    "    - Might want to export the model to another serving system or custom application to do it\n",
    "    \n",
    "**Spark Structual Types**\n",
    "- Transformers: functions convert raw data in some way\n",
    "- Estimators\n",
    "    - can a a kind of transformer than is initialized data, e.g. normalize data need to get the mean and std from data\n",
    "    - algorithms that allow users to train a model from data\n",
    "- Evaluator: provide insight about how a model performs according to some criteria we specified such as AUC.\n",
    "- Pipeline: a container hat pipelining the process, like the scikit-learn pipeline\n",
    "\n",
    "\n",
    "**Spark Low Level Data Types**\n",
    "- `from pyspark.ml.linalg import Vectors`\n",
    "- Dense Vector: `Vector.dense(1.0, 2.0, 3.0)`\n",
    "- Spark Vector: `Vector.sparse(size, idx, values)` idx for positions that is not zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example Walk Through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://unknown40A5EF2BBD8A:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MLexample</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe044606dd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "data_example_path = '/home/jgeng/Documents/Git/SparkLearning/data/simple-ml' \n",
    "spark = SparkSession.builder.appName('MLexample').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = spark.read.json(data_example_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+\n",
      "|color| lab|value1|            value2|\n",
      "+-----+----+------+------------------+\n",
      "|green|good|     1|14.386294994851129|\n",
      "| blue| bad|     8|14.386294994851129|\n",
      "| blue| bad|    12|14.386294994851129|\n",
      "+-----+----+------+------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- color: string (nullable = true)\n",
      " |-- lab: string (nullable = true)\n",
      " |-- value1: long (nullable = true)\n",
      " |-- value2: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, max, min, avg, stddev_samp\n",
    "\n",
    "# check on schema\n",
    "df.show(3)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check null\n",
    "for col_name in df.columns:\n",
    "    print(df.where('{} is null'.format(col_name)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|color|\n",
      "+-----+\n",
      "|green|\n",
      "|  red|\n",
      "| blue|\n",
      "+-----+\n",
      "\n",
      "+----+\n",
      "| lab|\n",
      "+----+\n",
      "| bad|\n",
      "|good|\n",
      "+----+\n",
      "\n",
      "+-------+------------------+------------------+\n",
      "|summary|            value1|            value2|\n",
      "+-------+------------------+------------------+\n",
      "|  count|               110|               110|\n",
      "|   mean|14.818181818181818|  21.0914521792258|\n",
      "| stddev|13.305294399193416|10.999588110596887|\n",
      "|    min|                 1|14.386294994851129|\n",
      "|    25%|                 2|14.386294994851129|\n",
      "|    50%|                12|14.386294994851129|\n",
      "|    75%|                16| 38.97187133755819|\n",
      "|    max|                45| 38.97187133755819|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col('color')).distinct().show(3)\n",
    "df.select(col('lab')).distinct().show(3)\n",
    "df.select('value1', 'value2').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
