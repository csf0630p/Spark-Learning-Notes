{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Learning Note - Data Aggregations and Table Joining\n",
    "\n",
    "Jia Geng | gjia0214@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_252\"\r\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~19.10-b09)\r\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\r\n"
     ]
    }
   ],
   "source": [
    "# check java version \n",
    "# use sudo update-alternatives --config java to switch java version if needed.\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://unknown40A5EF2BBD8A:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Learning</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa6bc798f90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Spark Learning').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_example = '/home/jgeng/Documents/Git/SparkLearning/book_data/retail-data/all/online-retail-dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "Aggregation is to group the rows by a key and grouping function. In spark, the groupby operation will return a `RelationalGroupedDataset` object.\n",
    "\n",
    "Grouping types in spark include:\n",
    "- summary of whole DataFrame, e.g. `df.count()`\n",
    "- **group by**: Aggregate using one or more keys and one or more grouping functions\n",
    "- **window**: Aggregate using one or more keys and one or more grouping functions. Functions are related to the current row.\n",
    "- **group set**: Aggregate at multiple different levels\n",
    "    - **roll up**: one or more keys and one or more values, summarized hierarchically\n",
    "    - **cube**: one or more keys and one or more values, summarized across all combinations of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.format('csv').option('header', True).option('inferSchema', True).load(data_example)\n",
    "df.printSchema()\n",
    "df.show(3)\n",
    "df.cache()  # cache is lazy operation, it does not cache data until use it\n",
    "df.count()  # since count is an action on all data, call this will cache all data on memory!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Aggregation Functions on DataFrame\n",
    "\n",
    "Common aggregation functions on dataframes are under `pyspark.sql.functions`. Work on columns.\n",
    "- `count()`: `df.count()` if action. `count(col)` is transformation.\n",
    "- `countDistinct()`: can be slow when data is large\n",
    "- `approx_count_distinct(col_name, prec)`: faster option, take a precision param\n",
    "- `first()`, `last()`: get first/last value of a column\n",
    "- `min()`, `max()`, `sum()`, `sumDistinct()`, `avg()`: work as it means\n",
    "- `var_pop()`, `var_sample()`, `stddev_pop()`, `stddev_sample()`: work as it means\n",
    "- `skewness()`, `kirtosis()`\n",
    "    - skewness: \n",
    "    - kirtosis: \n",
    "- `corr()`, `covar_pop()`, `covar_sample()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
